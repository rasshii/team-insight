# ãƒ‡ãƒ—ãƒ­ã‚¤ã¨é‹ç”¨

**ã“ã®ã‚¬ã‚¤ãƒ‰ã§å­¦ã¹ã‚‹ã“ã¨**ï¼š
- Docker/Docker Composeã‚’ä½¿ã£ãŸæœ¬ç•ªç’°å¢ƒæ§‹ç¯‰
- ç’°å¢ƒå¤‰æ•°ã¨ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆç®¡ç†
- ç›£è¦–ã¨ãƒ­ã‚®ãƒ³ã‚°ã®è¨­å®š
- ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¨ãƒªã‚¹ãƒˆã‚¢æˆ¦ç•¥

## ğŸ³ Dockerç’°å¢ƒã®ç†è§£

### Docker Composeã®æ§‹æˆ

```yaml
# docker-compose.ymlï¼ˆæœ¬ç•ªç”¨ã®æœ€é©åŒ–ç‰ˆï¼‰
version: '3.8'

services:
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - static_files:/usr/share/nginx/html/static
    depends_on:
      - frontend
      - backend
    restart: always
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  frontend:
    build:
      context: ./frontend
      dockerfile: ../infrastructure/docker/frontend/Dockerfile.prod
      args:
        - NEXT_PUBLIC_API_URL=${FRONTEND_API_URL}
    environment:
      - NODE_ENV=production
    restart: always
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  backend:
    build:
      context: ./backend
      dockerfile: ../infrastructure/docker/backend/Dockerfile.prod
    env_file:
      - ./backend/.env.production
    environment:
      - PYTHONUNBUFFERED=1
      - APP_ENV=production
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: always
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  postgres:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: ${DB_NAME}
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./infrastructure/postgres/init.sql:/docker-entrypoint-initdb.d/init.sql:ro
    restart: always
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER}"]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    command: redis-server --requirepass ${REDIS_PASSWORD}
    volumes:
      - redis_data:/data
    restart: always
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

volumes:
  postgres_data:
  redis_data:
  static_files:

networks:
  default:
    driver: bridge
```

### æœ¬ç•ªç”¨Dockerfile

#### ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰

```dockerfile
# infrastructure/docker/backend/Dockerfile.prod
# ãƒãƒ«ãƒã‚¹ãƒ†ãƒ¼ã‚¸ãƒ“ãƒ«ãƒ‰
FROM python:3.11-slim as builder

WORKDIR /app

# ãƒ“ãƒ«ãƒ‰ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    libpq-dev \
    && rm -rf /var/lib/apt/lists/*

# ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
COPY requirements.txt .
RUN pip install --user --no-cache-dir -r requirements.txt

# æœ¬ç•ªã‚¤ãƒ¡ãƒ¼ã‚¸
FROM python:3.11-slim

WORKDIR /app

# å®Ÿè¡Œæ™‚ã«å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã¿ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
RUN apt-get update && apt-get install -y \
    libpq5 \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Pythonãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚³ãƒ”ãƒ¼
COPY --from=builder /root/.local /root/.local

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚³ãƒ¼ãƒ‰ã‚’ã‚³ãƒ”ãƒ¼
COPY . .

# érootãƒ¦ãƒ¼ã‚¶ãƒ¼ã§å®Ÿè¡Œ
RUN useradd -m -u 1000 appuser && chown -R appuser:appuser /app
USER appuser

# PATHç’°å¢ƒå¤‰æ•°ã‚’æ›´æ–°
ENV PATH=/root/.local/bin:$PATH

# Gunicornã§èµ·å‹•
CMD ["gunicorn", "app.main:app", \
     "--workers", "4", \
     "--worker-class", "uvicorn.workers.UvicornWorker", \
     "--bind", "0.0.0.0:8000", \
     "--access-logfile", "-", \
     "--error-logfile", "-"]
```

#### ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰

```dockerfile
# infrastructure/docker/frontend/Dockerfile.prod
# ãƒ“ãƒ«ãƒ‰ã‚¹ãƒ†ãƒ¼ã‚¸
FROM node:18-alpine as builder

WORKDIR /app

# ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
COPY package.json yarn.lock .yarnrc.yml ./
COPY .yarn .yarn
RUN yarn install --frozen-lockfile

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ“ãƒ«ãƒ‰
COPY . .
ARG NEXT_PUBLIC_API_URL
ENV NEXT_PUBLIC_API_URL=$NEXT_PUBLIC_API_URL
RUN yarn build

# æœ¬ç•ªã‚¤ãƒ¡ãƒ¼ã‚¸
FROM node:18-alpine

WORKDIR /app

# æœ¬ç•ªç”¨ã®ä¾å­˜é–¢ä¿‚ã®ã¿ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
COPY package.json yarn.lock .yarnrc.yml ./
COPY .yarn .yarn
RUN yarn workspaces focus --production && yarn cache clean

# ãƒ“ãƒ«ãƒ‰æˆæœç‰©ã‚’ã‚³ãƒ”ãƒ¼
COPY --from=builder /app/.next ./.next
COPY --from=builder /app/public ./public
COPY --from=builder /app/next.config.js ./

# érootãƒ¦ãƒ¼ã‚¶ãƒ¼ã§å®Ÿè¡Œ
RUN addgroup -g 1001 -S nodejs
RUN adduser -S nextjs -u 1001
USER nextjs

EXPOSE 3000

CMD ["yarn", "start"]
```

### Nginxè¨­å®š

```nginx
# nginx/nginx.conf
user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

events {
    worker_connections 1024;
    use epoll;
    multi_accept on;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    # ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for" '
                    'rt=$request_time uct="$upstream_connect_time" '
                    'uht="$upstream_header_time" urt="$upstream_response_time"';

    access_log /var/log/nginx/access.log main;

    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨­å®š
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;
    client_max_body_size 20M;

    # Gzipåœ§ç¸®
    gzip on;
    gzip_vary on;
    gzip_proxied any;
    gzip_comp_level 6;
    gzip_types text/plain text/css text/xml text/javascript 
               application/json application/javascript application/xml+rss;

    # ãƒ¬ãƒ¼ãƒˆåˆ¶é™
    limit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;
    limit_req_zone $binary_remote_addr zone=auth:10m rate=5r/m;

    # ã‚¢ãƒƒãƒ—ã‚¹ãƒˆãƒªãƒ¼ãƒ å®šç¾©
    upstream frontend {
        server frontend:3000;
        keepalive 32;
    }

    upstream backend {
        server backend:8000;
        keepalive 32;
    }

    # HTTPSãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆ
    server {
        listen 80;
        server_name _;
        return 301 https://$host$request_uri;
    }

    # HTTPSè¨­å®š
    server {
        listen 443 ssl http2;
        server_name team-insight.example.com;

        # SSLè¨­å®š
        ssl_certificate /etc/nginx/ssl/cert.pem;
        ssl_certificate_key /etc/nginx/ssl/key.pem;
        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384;
        ssl_prefer_server_ciphers off;
        ssl_session_cache shared:SSL:10m;
        ssl_session_timeout 10m;

        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ˜ãƒƒãƒ€ãƒ¼
        add_header X-Frame-Options "SAMEORIGIN" always;
        add_header X-Content-Type-Options "nosniff" always;
        add_header X-XSS-Protection "1; mode=block" always;
        add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;

        # API endpoints
        location /api/ {
            limit_req zone=api burst=20 nodelay;
            
            proxy_pass http://backend;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "upgrade";
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®š
            proxy_connect_timeout 30s;
            proxy_send_timeout 30s;
            proxy_read_timeout 30s;
        }

        # èªè¨¼ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¯åˆ¥ã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™
        location /api/v1/auth/ {
            limit_req zone=auth burst=5 nodelay;
            
            proxy_pass http://backend;
            proxy_http_version 1.1;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }

        # é™çš„ãƒ•ã‚¡ã‚¤ãƒ«
        location /_next/static/ {
            alias /usr/share/nginx/html/static/;
            expires 1y;
            add_header Cache-Control "public, immutable";
        }

        # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰
        location / {
            proxy_pass http://frontend;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "upgrade";
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }

        # ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
        location /health {
            access_log off;
            default_type text/plain;
            return 200 "healthy\n";
        }
    }
}

## ğŸ” ç’°å¢ƒå¤‰æ•°ã¨ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆç®¡ç†

### ç’°å¢ƒå¤‰æ•°ã®éšå±¤

```
1. ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ï¼ˆã‚³ãƒ¼ãƒ‰å†…ï¼‰
2. .env.productionï¼ˆãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†å¤–ï¼‰
3. Docker Composeç’°å¢ƒå¤‰æ•°
4. ã‚³ãƒ³ãƒ†ãƒŠå®Ÿè¡Œæ™‚ã®ç’°å¢ƒå¤‰æ•°
5. ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆç®¡ç†ãƒ„ãƒ¼ãƒ«ï¼ˆAWS Secrets Managerç­‰ï¼‰
```

### æœ¬ç•ªç’°å¢ƒã®ç’°å¢ƒå¤‰æ•°

```bash
# backend/.env.production
# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
DATABASE_URL=postgresql://${DB_USER}:${DB_PASSWORD}@postgres:5432/${DB_NAME}
DB_POOL_SIZE=20
DB_MAX_OVERFLOW=10

# Redis
REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379/0
REDIS_MAX_CONNECTIONS=50

# ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£
SECRET_KEY=${SECRET_KEY}  # å¿…ãšå¼·åŠ›ãªãƒ©ãƒ³ãƒ€ãƒ æ–‡å­—åˆ—
ALLOWED_HOSTS=team-insight.example.com,api.team-insight.example.com
CORS_ORIGINS=https://team-insight.example.com

# Backlog OAuth
BACKLOG_CLIENT_ID=${BACKLOG_CLIENT_ID}
BACKLOG_CLIENT_SECRET=${BACKLOG_CLIENT_SECRET}
BACKLOG_REDIRECT_URI=https://team-insight.example.com/api/v1/auth/callback
BACKLOG_SPACE_KEY=${BACKLOG_SPACE_KEY}

# ãƒ¡ãƒ¼ãƒ«è¨­å®šï¼ˆæœ¬ç•ªç”¨SMTPï¼‰
SMTP_HOST=smtp.sendgrid.net
SMTP_PORT=587
SMTP_USER=apikey
SMTP_PASSWORD=${SENDGRID_API_KEY}
SMTP_TLS=true
EMAIL_FROM=noreply@team-insight.example.com

# ãƒ­ã‚®ãƒ³ã‚°
LOG_LEVEL=INFO
SENTRY_DSN=${SENTRY_DSN}

# APScheduler
SCHEDULER_TIMEZONE=Asia/Tokyo
SCHEDULER_JOB_DEFAULTS_MISFIRE_GRACE_TIME=3600

# ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
WORKERS=4
WORKER_TIMEOUT=120
KEEPALIVE=5
```

### ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆç®¡ç†ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

#### 1. ç’°å¢ƒå¤‰æ•°ã®æš—å·åŒ–

```bash
# .env.encryptedã‚’ä½œæˆ
openssl enc -aes-256-cbc -salt -in .env.production -out .env.encrypted -k $ENCRYPTION_KEY

# å¾©å·åŒ–
openssl enc -aes-256-cbc -d -in .env.encrypted -out .env.production -k $ENCRYPTION_KEY
```

#### 2. Docker Secretsã®ä½¿ç”¨

```yaml
# docker-compose.secrets.yml
version: '3.8'

secrets:
  db_password:
    external: true
  redis_password:
    external: true
  secret_key:
    external: true
  backlog_client_secret:
    external: true

services:
  backend:
    secrets:
      - db_password
      - redis_password
      - secret_key
      - backlog_client_secret
    environment:
      - DB_PASSWORD_FILE=/run/secrets/db_password
      - REDIS_PASSWORD_FILE=/run/secrets/redis_password
      - SECRET_KEY_FILE=/run/secrets/secret_key
```

#### 3. HashiCorp Vaultã®çµ±åˆ

```python
# backend/app/core/vault.py
import hvac
from typing import Dict, Any
import os

class VaultClient:
    """HashiCorp Vaultã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"""
    
    def __init__(self):
        self.client = hvac.Client(
            url=os.getenv('VAULT_ADDR', 'http://vault:8200'),
            token=os.getenv('VAULT_TOKEN')
        )
    
    def get_secrets(self, path: str) -> Dict[str, Any]:
        """ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‚’å–å¾—"""
        try:
            response = self.client.secrets.kv.v2.read_secret_version(
                path=path,
                mount_point='secret'
            )
            return response['data']['data']
        except Exception as e:
            logger.error(f"Failed to fetch secrets from Vault: {e}")
            raise
    
    def get_database_credentials(self) -> Dict[str, str]:
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹èªè¨¼æƒ…å ±ã‚’å–å¾—"""
        secrets = self.get_secrets('team-insight/database')
        return {
            'username': secrets['username'],
            'password': secrets['password'],
            'host': secrets['host'],
            'port': secrets['port'],
            'database': secrets['database']
        }

# ä½¿ç”¨ä¾‹
if os.getenv('USE_VAULT', 'false').lower() == 'true':
    vault_client = VaultClient()
    db_creds = vault_client.get_database_credentials()
    DATABASE_URL = f"postgresql://{db_creds['username']}:{db_creds['password']}@{db_creds['host']}:{db_creds['port']}/{db_creds['database']}"
else:
    DATABASE_URL = os.getenv('DATABASE_URL')
```

## ğŸš€ ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆãƒ—ãƒ­ã‚»ã‚¹

### 1. ãƒ“ãƒ«ãƒ‰ã¨ãƒ—ãƒƒã‚·ãƒ¥

```bash
#!/bin/bash
# scripts/deploy.sh

set -e

# ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚¿ã‚°
VERSION=${1:-latest}
REGISTRY="your-registry.com"

echo "Building images with version: $VERSION"

# ãƒ“ãƒ«ãƒ‰
docker-compose -f docker-compose.prod.yml build

# ã‚¿ã‚°ä»˜ã‘
docker tag team-insight-backend:latest $REGISTRY/team-insight-backend:$VERSION
docker tag team-insight-frontend:latest $REGISTRY/team-insight-frontend:$VERSION

# ãƒ¬ã‚¸ã‚¹ãƒˆãƒªã«ãƒ—ãƒƒã‚·ãƒ¥
docker push $REGISTRY/team-insight-backend:$VERSION
docker push $REGISTRY/team-insight-frontend:$VERSION

echo "Images pushed successfully"
```

### 2. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

```bash
#!/bin/bash
# scripts/migrate.sh

echo "Running database migrations..."

# æœ¬ç•ªç’°å¢ƒã§ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
docker-compose -f docker-compose.prod.yml run --rm backend \
    alembic upgrade head

echo "Migrations completed"
```

### 3. Blue-Greenãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ

```yaml
# docker-compose.blue-green.yml
version: '3.8'

services:
  # Blueç’°å¢ƒï¼ˆç¾åœ¨ç¨¼åƒä¸­ï¼‰
  backend-blue:
    image: ${REGISTRY}/team-insight-backend:${CURRENT_VERSION}
    environment:
      - SERVICE_COLOR=blue
    networks:
      - backend-net
    deploy:
      replicas: 2

  # Greenç’°å¢ƒï¼ˆæ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ï¼‰
  backend-green:
    image: ${REGISTRY}/team-insight-backend:${NEW_VERSION}
    environment:
      - SERVICE_COLOR=green
    networks:
      - backend-net
    deploy:
      replicas: 2

  # ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼
  nginx:
    image: nginx:alpine
    volumes:
      - ./nginx/blue-green.conf:/etc/nginx/nginx.conf:ro
    ports:
      - "80:80"
    networks:
      - backend-net
```

### 4. ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã¨ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯

```python
# scripts/health_check.py
import requests
import time
import sys

def check_health(url: str, retries: int = 30, delay: int = 10):
    """ãƒ‡ãƒ—ãƒ­ã‚¤å¾Œã®ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
    
    for i in range(retries):
        try:
            response = requests.get(f"{url}/health", timeout=5)
            if response.status_code == 200:
                data = response.json()
                if data.get('status') == 'healthy':
                    print(f"âœ“ Health check passed: {data}")
                    return True
        except Exception as e:
            print(f"Health check attempt {i+1}/{retries} failed: {e}")
        
        time.sleep(delay)
    
    return False

def check_critical_endpoints(base_url: str):
    """é‡è¦ãªã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ç¢ºèª"""
    
    endpoints = [
        "/api/v1/projects",
        "/api/v1/users/me",
        "/api/v1/sync/connection/status"
    ]
    
    for endpoint in endpoints:
        try:
            response = requests.get(
                f"{base_url}{endpoint}",
                headers={"Authorization": f"Bearer {test_token}"},
                timeout=10
            )
            if response.status_code not in [200, 401]:  # 401ã¯èªè¨¼ãŒå¿…è¦
                print(f"âœ— Endpoint check failed: {endpoint} - {response.status_code}")
                return False
            print(f"âœ“ Endpoint check passed: {endpoint}")
        except Exception as e:
            print(f"âœ— Endpoint check failed: {endpoint} - {e}")
            return False
    
    return True

if __name__ == "__main__":
    service_url = sys.argv[1] if len(sys.argv) > 1 else "http://localhost"
    
    # ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
    if not check_health(service_url):
        print("Health check failed! Rolling back...")
        sys.exit(1)
    
    # ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãƒã‚§ãƒƒã‚¯
    if not check_critical_endpoints(service_url):
        print("Endpoint check failed! Rolling back...")
        sys.exit(1)
    
    print("All checks passed! Deployment successful.")
```

## ğŸ”§ æœ¬ç•ªç’°å¢ƒã®æœ€é©åŒ–

### PostgreSQLè¨­å®š

```sql
-- postgresql.conf ã®æ¨å¥¨è¨­å®š
-- ãƒ¡ãƒ¢ãƒªè¨­å®šï¼ˆ8GBãƒ¡ãƒ¢ãƒªã‚µãƒ¼ãƒãƒ¼ã®å ´åˆï¼‰
shared_buffers = 2GB
effective_cache_size = 6GB
maintenance_work_mem = 512MB
work_mem = 10MB

-- æ¥ç¶šè¨­å®š
max_connections = 200
max_prepared_transactions = 0

-- ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆè¨­å®š
checkpoint_segments = 32
checkpoint_completion_target = 0.9

-- ãƒ­ã‚°è¨­å®š
log_statement = 'mod'
log_duration = on
log_min_duration_statement = 1000  -- 1ç§’ä»¥ä¸Šã®ã‚¯ã‚¨ãƒªã‚’ãƒ­ã‚°

-- è‡ªå‹•ãƒã‚­ãƒ¥ãƒ¼ãƒ 
autovacuum = on
autovacuum_max_workers = 4
```

### Redisè¨­å®š

```conf
# redis.conf
# ãƒ¡ãƒ¢ãƒªè¨­å®š
maxmemory 2gb
maxmemory-policy allkeys-lru

# æ°¸ç¶šåŒ–
save 900 1
save 300 10
save 60 10000

# AOF
appendonly yes
appendfsync everysec

# ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£
requirepass your-redis-password
```

## ğŸ“Š ç›£è¦–ã¨ãƒ­ã‚®ãƒ³ã‚°

### Prometheusã«ã‚ˆã‚‹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ç›£è¦–

```yaml
# docker-compose.monitoring.yml
version: '3.8'

services:
  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    ports:
      - "9090:9090"
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards
```

### ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¡ãƒˆãƒªã‚¯ã‚¹

```python
# backend/app/core/metrics.py
from prometheus_client import Counter, Histogram, Gauge
import time

# ãƒ¡ãƒˆãƒªã‚¯ã‚¹å®šç¾©
request_count = Counter(
    'http_requests_total',
    'Total HTTP requests',
    ['method', 'endpoint', 'status']
)

request_duration = Histogram(
    'http_request_duration_seconds',
    'HTTP request duration',
    ['method', 'endpoint']
)

active_users = Gauge(
    'active_users',
    'Number of active users'
)

sync_operations = Counter(
    'sync_operations_total',
    'Total sync operations',
    ['type', 'status']
)
```

### ãƒ­ã‚°é›†ç´„ï¼ˆELK Stackï¼‰

```yaml
# docker-compose.logging.yml
services:
  elasticsearch:
    image: elasticsearch:8.11.0
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    volumes:
      - es_data:/usr/share/elasticsearch/data

  logstash:
    image: logstash:8.11.0
    volumes:
      - ./logstash/pipeline:/usr/share/logstash/pipeline
    depends_on:
      - elasticsearch

  kibana:
    image: kibana:8.11.0
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    ports:
      - "5601:5601"
```

## ğŸ’¾ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¨ãƒªã‚¹ãƒˆã‚¢

### è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

```bash
#!/bin/bash
# scripts/backup.sh

BACKUP_DIR="/backups"
TIMESTAMP=$(date +%Y%m%d_%H%M%S)

# PostgreSQLãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
docker-compose exec -T postgres pg_dump -U teaminsight teaminsight | \
    gzip > "$BACKUP_DIR/postgres_${TIMESTAMP}.sql.gz"

# Redisãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
docker-compose exec -T redis redis-cli --rdb /data/dump.rdb
docker cp $(docker-compose ps -q redis):/data/dump.rdb \
    "$BACKUP_DIR/redis_${TIMESTAMP}.rdb"

# ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
tar -czf "$BACKUP_DIR/uploads_${TIMESTAMP}.tar.gz" /app/uploads

# S3ã¸ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
aws s3 cp "$BACKUP_DIR/" s3://team-insight-backups/ --recursive \
    --exclude "*" --include "*_${TIMESTAMP}*"

# å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®å‰Šé™¤ï¼ˆ30æ—¥ä»¥ä¸Šï¼‰
find "$BACKUP_DIR" -type f -mtime +30 -delete
```

### ãƒªã‚¹ãƒˆã‚¢æ‰‹é †

```bash
#!/bin/bash
# scripts/restore.sh

BACKUP_DATE=$1

# PostgreSQLãƒªã‚¹ãƒˆã‚¢
gunzip -c "/backups/postgres_${BACKUP_DATE}.sql.gz" | \
    docker-compose exec -T postgres psql -U teaminsight

# Redisãƒªã‚¹ãƒˆã‚¢
docker cp "/backups/redis_${BACKUP_DATE}.rdb" \
    $(docker-compose ps -q redis):/data/dump.rdb
docker-compose restart redis
```

---

æ¬¡ã¯[ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°](10-troubleshooting.md)ã§ã€å•é¡Œè§£æ±ºã®æ–¹æ³•ã‚’å­¦ã³ã¾ã—ã‚‡ã†ï¼
```